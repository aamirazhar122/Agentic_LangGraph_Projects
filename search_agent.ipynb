{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import  TypedDict, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from pydantic import BaseModel\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search(query : str) -> str :\n",
    "#     \"\"\"call to surf the web and useful for performing online searches when specific information is required.\"\"\"\n",
    "#     return(\"the answer of your query lies within, \")\n",
    "\n",
    "# tools = [search]\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "# search_tool = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "        search_result : str\n",
    "        sub_tasks : List [str]\n",
    "        combine_results : str        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_down_query(state: State):\n",
    "    ''' Break the user complex questions/queries into smaller, actionable tasks. \n",
    "    Example :\n",
    "        Question: \"What are the top 3 hiking destinations in Asia and the best travel options?\"\n",
    "            Task 1: Find top hiking destinations in Asia.\n",
    "            Task 2: Search for travel options to those destinations.  '''\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = [\"search_result\"],\n",
    "        template = \"Break the user complex questions/queries into smaller, actionable tasks.\\n\\nSearch_Result:{search_result}\\n\\n sub tasks :\"\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(text=state[\"search_result\"]))\n",
    "    sub_tasks = llm.invoke([message]).content.strip()\n",
    "    return {\"Sub Tasks\":  sub_tasks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_response(state: State):\n",
    "    ''' Break the user complex questions/queries into smaller, actionable tasks. \n",
    "    Example :\n",
    "        Question: \"What are the top 3 hiking destinations in Asia and the best travel options?\"\n",
    "            Task 1: Find top hiking destinations in Asia.\n",
    "            Task 2: Search for travel options to those destinations.  '''\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = [\"search_result\"],\n",
    "        template = \"Break the user complex questions/queries into smaller, actionable tasks.\\n\\nSearch_Result:{search_result}\\n\\n sub tasks :\"\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(text=state[\"search_result\"]))\n",
    "    sub_tasks = llm.invoke([message]).content.strip()\n",
    "    return {\"Sub Tasks\":  sub_tasks}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
